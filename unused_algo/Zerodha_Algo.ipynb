{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T05:49:25.593949Z",
     "start_time": "2025-06-27T05:49:25.323701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "instruments = broker.kite.instruments(\"NSE\")\n",
    "matches = [i for i in instruments if \"HDFC\" in i[\"tradingsymbol\"]]\n",
    "for m in matches:\n",
    "    print(m[\"tradingsymbol\"], m[\"instrument_token\"])"
   ],
   "id": "c8e9d0f5f04f819d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDFCLIFE 119553\n",
      "HDFCBANK 341249\n",
      "HDFCAMC 1086465\n",
      "HDFCNEXT50 2718465\n",
      "HDFCNIF100 2722049\n",
      "HDFCSILVER 2784257\n",
      "HDFCGROWTH 2877697\n",
      "HDFCQUAL 2881281\n",
      "HDFCVALUE 2882561\n",
      "HDFCMOMENT 2953729\n",
      "HDFCLOWVOL 2956033\n",
      "HDFCNIFTY 2967297\n",
      "HDFCSENSEX 2967809\n",
      "HDFCNIFIT 3097857\n",
      "HDFCPVTBAN 3099649\n",
      "HDFCBSE500 3642881\n",
      "HDFCSML250 3643649\n",
      "HDFCMID150 3644417\n",
      "HDFCLIQUID 4679425\n",
      "HDFCGOLD 5003009\n",
      "771HDFCB33-N0 5312769\n",
      "HDFCNIFBAN 5742849\n",
      "HDFCPSUBK 5784321\n",
      "765HDFC34-N1 5944833\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data log of entries, exits and P&L",
   "id": "f806b577-8ec3-4920-b89e-1af9ba48457f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:46:01.695820Z",
     "start_time": "2025-06-24T09:46:01.678512Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side                entry_time                 exit_time  entry_price  exit_price  qty  notional    pnl        duration\n",
      " BUY 2025-04-25 15:00:00+05:30 2025-04-28 13:15:00+05:30       1303.6      1368.9    7    9125.2  457.1 2 days 22:15:00\n",
      " BUY 2025-04-28 14:20:00+05:30 2025-05-05 09:40:00+05:30       1366.1      1438.4    7    9562.7  506.1 6 days 19:20:00\n",
      " BUY 2025-05-05 10:10:00+05:30 2025-05-06 11:15:00+05:30       1435.5      1412.0    6    8613.0 -141.0 1 days 01:05:00\n",
      "SELL 2025-05-08 09:50:00+05:30 2025-05-12 13:40:00+05:30       1409.8      1431.0    7    9868.6 -148.4 4 days 03:50:00\n",
      " BUY 2025-05-13 09:20:00+05:30 2025-05-22 09:45:00+05:30       1431.0      1408.4    6    8586.0 -135.6 9 days 00:25:00\n",
      " BUY 2025-05-23 11:10:00+05:30 2025-06-02 09:15:00+05:30       1430.5      1401.1    6    8583.0 -176.4 9 days 22:05:00\n",
      "SELL 2025-06-02 09:40:00+05:30 2025-06-03 10:20:00+05:30       1400.5      1422.5    7    9803.5 -154.0 1 days 00:40:00\n",
      " BUY 2025-06-05 11:20:00+05:30 2025-06-13 09:20:00+05:30       1443.7      1419.8    6    8662.2 -143.4 7 days 22:00:00\n",
      "\n",
      "TOTAL PnL: ‚Çπ64.40\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "import pandas as pd\n",
    "\n",
    "# bt_df is the DataFrame returned by backtest()\n",
    "contract_size = 1  # for equity\n",
    "\n",
    "# Make sure bt_df is indexed by the `date` column:\n",
    "df = bt_df.set_index(\"date\")\n",
    "\n",
    "# Extract entry & exit rows\n",
    "entries = df[df.signal.isin([\"BUY\",\"SELL\"])].copy()\n",
    "exits   = df[df.signal == \"EXIT\"].copy()\n",
    "\n",
    "trades = []\n",
    "# Iterate over matching entry/exit pairs\n",
    "for (entry_time, ent_row), (exit_time, ex_row) in zip(entries.iterrows(), exits.iterrows()):\n",
    "    side        = ent_row.signal\n",
    "    entry_price = ent_row.close\n",
    "    exit_price  = ex_row.close\n",
    "    qty         = int(ent_row.qty)\n",
    "    notional    = entry_price * qty * contract_size\n",
    "    pnl         = float(ex_row.pnl)\n",
    "    duration    = exit_time - entry_time\n",
    "\n",
    "    trades.append({\n",
    "        \"side\":        side,\n",
    "        \"entry_time\":  entry_time,   # now a Timestamp\n",
    "        \"exit_time\":   exit_time,    # now a Timestamp\n",
    "        \"entry_price\": entry_price,\n",
    "        \"exit_price\":  exit_price,\n",
    "        \"qty\":         qty,\n",
    "        \"notional\":    notional,\n",
    "        \"pnl\":         pnl,\n",
    "        \"duration\":    duration,\n",
    "    })\n",
    "\n",
    "report = pd.DataFrame(trades)\n",
    "print(report.to_string(index=False))\n",
    "print(f\"\\nTOTAL PnL: ‚Çπ{report.pnl.sum():.2f}\")"
   ],
   "id": "e300d673-eae7-4a40-bc5b-e5045b5b6994"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T08:18:43.166559Z",
     "start_time": "2025-06-27T08:18:26.200821Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1Ô∏è‚É£ Imports\n",
    "from algo.broker       import KiteWrapper\n",
    "from algo.config       import load_config\n",
    "from algo.features     import add_indicators\n",
    "from algo.model        import load_or_train\n",
    "from algo.backtester   import backtest\n",
    "import pandas as pd\n",
    "\n",
    "# 2Ô∏è‚É£ Parameters\n",
    "SYMBOL     = \"HDFCBANK\"\n",
    "INTERVAL   = \"3minute\"\n",
    "TRAIN_DAYS = 180\n",
    "TEST_DAYS  = 20\n",
    "\n",
    "CAPITAL    = 100_000\n",
    "SL_PCT     = 0.0015\n",
    "TP_PCT     = 0.0025\n",
    "TRAIL_PCT  = 0.0020\n",
    "HOLD_MAX   = 15\n",
    "\n",
    "UPPER_PROB = 0.62\n",
    "LOWER_PROB = 0.32\n",
    "\n",
    "# 3Ô∏è‚É£ Fetch & prepare training data\n",
    "cfg        = load_config()\n",
    "broker     = KiteWrapper(cfg)\n",
    "\n",
    "hist_train = broker.history(\n",
    "    days=TRAIN_DAYS,\n",
    "    interval=INTERVAL,\n",
    "    tradingsymbol=SYMBOL\n",
    ")\n",
    "df_train = add_indicators(hist_train).ffill()\n",
    "\n",
    "# 4Ô∏è‚É£ Load or retrain model (retrain=False will reuse your new pipeline)\n",
    "model = load_or_train(df_train, retrain=False)\n",
    "\n",
    "# 5Ô∏è‚É£ Fetch & prepare test slice\n",
    "hist_test = broker.history(\n",
    "    days=TEST_DAYS,\n",
    "    interval=INTERVAL,\n",
    "    tradingsymbol=SYMBOL\n",
    ")\n",
    "df_test = add_indicators(hist_test).ffill()\n",
    "\n",
    "# 6Ô∏è‚É£ Run backtest\n",
    "trades, metrics = backtest(\n",
    "    df_test,\n",
    "    model=model,\n",
    "    capital=CAPITAL,\n",
    "    contract_size=1,\n",
    "    sl_pct=SL_PCT,\n",
    "    tp_pct=TP_PCT,\n",
    "    trail_pct=TRAIL_PCT,\n",
    "    hold_max=HOLD_MAX,\n",
    "    upper=UPPER_PROB,\n",
    "    lower=LOWER_PROB,\n",
    ")\n",
    "\n",
    "# 7Ô∏è‚É£ Review results\n",
    "print(\"Back-test metrics:\", metrics)\n",
    "print(\"\\nFirst few trades:\\n\", trades.head())\n"
   ],
   "id": "97f873867e5bc630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Back-test metrics: {'Trades': 24.0, 'WinRate': 0.375, 'PnL': 800.9007782652479, 'EquityFinal': 100800.90077826525}\n",
      "\n",
      "First few trades:\n",
      "                            side   price         pnl        equity reason\n",
      "ts                                                                      \n",
      "2025-06-09 13:06:00+05:30   BUY  1979.6   -0.593880  99999.406120       \n",
      "2025-06-09 13:51:00+05:30  EXIT  1979.4  -10.696871  99988.709249   TIME\n",
      "2025-06-09 14:00:00+05:30   BUY  1980.1   -0.594030  99988.115219       \n",
      "2025-06-09 14:24:00+05:30  EXIT  1975.9 -212.703269  99775.411949     SL\n",
      "2025-06-09 14:33:00+05:30   BUY  1978.7   -0.593610  99774.818339       \n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-06-27T17:58:06.286838Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from algo.broker     import KiteWrapper\n",
    "from algo.config     import load_config\n",
    "from algo.features   import add_indicators\n",
    "from algo.model      import _prepare_xy\n",
    "from algo.backtester import backtest\n",
    "\n",
    "from sklearn.pipeline        import Pipeline\n",
    "from sklearn.impute          import SimpleImputer\n",
    "from sklearn.preprocessing   import StandardScaler\n",
    "from sklearn.ensemble        import GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 1) Fetch & feature-engineer ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "cfg    = load_config()\n",
    "broker = KiteWrapper(cfg)\n",
    "hist   = broker.history(days=200, interval=\"3minute\", tradingsymbol=\"HDFCBANK\")\n",
    "df     = add_indicators(hist).ffill()\n",
    "\n",
    "# split off final TEST_DAYS for out-of-sample\n",
    "TEST_DAYS = 60\n",
    "df_train, df_test = df.iloc[:-TEST_DAYS], df.iloc[-TEST_DAYS:]\n",
    "\n",
    "# prepare X/y for ML\n",
    "X_all, y_all = _prepare_xy(df_train)\n",
    "Xtr, Xv, ytr, yv = train_test_split(X_all, y_all, test_size=0.2, shuffle=False)\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 2) Define search space ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "ml_grid = {\n",
    "    \"n_estimators\":  [50, 100, 200],\n",
    "    \"max_depth\":     [3, 5, 7],\n",
    "    \"learning_rate\": [0.01, 0.05, 0.1],\n",
    "    \"subsample\":     [0.6, 0.8, 1.0],\n",
    "}\n",
    "\n",
    "strat_grid = {\n",
    "    \"sl_pct\":    [0.0005, 0.001, 0.0015, 0.002],\n",
    "    \"tp_pct\":    [0.001, 0.002, 0.0025, 0.003],\n",
    "    \"trail_pct\": [0.001, 0.0015, 0.002, 0.0025],\n",
    "    \"hold_max\":  [5, 10, 15, 20],\n",
    "    \"upper\":     [0.55, 0.6, 0.65, 0.7],\n",
    "    \"lower\":     [0.3, 0.35, 0.4, 0.45],\n",
    "}\n",
    "\n",
    "# build full list of all possible combos\n",
    "all_combos = list(itertools.product(\n",
    "    ml_grid[\"n_estimators\"],\n",
    "    ml_grid[\"max_depth\"],\n",
    "    ml_grid[\"learning_rate\"],\n",
    "    ml_grid[\"subsample\"],\n",
    "    strat_grid[\"sl_pct\"],\n",
    "    strat_grid[\"tp_pct\"],\n",
    "    strat_grid[\"trail_pct\"],\n",
    "    strat_grid[\"hold_max\"],\n",
    "    strat_grid[\"upper\"],\n",
    "    strat_grid[\"lower\"],\n",
    "))\n",
    "\n",
    "# randomly sample N_SAMPLES combos\n",
    "N_SAMPLES = 50\n",
    "sampled = random.sample(all_combos, k=min(N_SAMPLES, len(all_combos)))\n",
    "\n",
    "def make_pipe(params):\n",
    "    return Pipeline([\n",
    "        (\"imputer\", SimpleImputer()),\n",
    "        (\"scaler\",  StandardScaler()),\n",
    "        (\"gb\",      GradientBoostingClassifier(**params)),\n",
    "    ])\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 3) Search loop with progress bar ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "results = []\n",
    "start = time.time()\n",
    "\n",
    "for (n_est, depth, lr, subs,\n",
    "     sl_pct, tp_pct, trail_pct,\n",
    "     hold_max, upper, lower) in tqdm(\n",
    "    sampled,\n",
    "    total=len(sampled),\n",
    "    desc=\"Hyper-search\",\n",
    "    unit=\"combo\"\n",
    "):\n",
    "    # ‚ë† train a fresh GB model\n",
    "    gb_params = {\n",
    "        \"n_estimators\":  n_est,\n",
    "        \"max_depth\":     depth,\n",
    "        \"learning_rate\": lr,\n",
    "        \"subsample\":     subs,\n",
    "    }\n",
    "    pipe = make_pipe(gb_params).fit(Xtr, ytr)\n",
    "\n",
    "    # ‚ë° backtest with these strategy settings\n",
    "    try:\n",
    "        _, m = backtest(\n",
    "            df_test,\n",
    "            model        = pipe,\n",
    "            capital      = 100_000,\n",
    "            contract_size= 1,\n",
    "            sl_pct       = sl_pct,\n",
    "            tp_pct       = tp_pct,\n",
    "            trail_pct    = trail_pct,\n",
    "            hold_max     = hold_max,\n",
    "            upper        = upper,\n",
    "            lower        = lower,\n",
    "        )\n",
    "        pnl, wr, trades = m[\"PnL\"], m[\"Win Rate\"], m[\"Trades\"]\n",
    "    except KeyError:\n",
    "        pnl, wr, trades = 0.0, 0.0, 0\n",
    "\n",
    "    # record results\n",
    "    results.append({\n",
    "        **gb_params,\n",
    "        \"sl_pct\":    sl_pct,\n",
    "        \"tp_pct\":    tp_pct,\n",
    "        \"trail_pct\": trail_pct,\n",
    "        \"hold_max\":  hold_max,\n",
    "        \"upper\":     upper,\n",
    "        \"lower\":     lower,\n",
    "        \"PnL\":       pnl,\n",
    "        \"Win Rate\":  wr,\n",
    "        \"Trades\":    trades,\n",
    "    })\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\\nSearched {len(sampled)} combos in {elapsed:.0f}s\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ 4) Collect & inspect ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "df_res = pd.DataFrame(results)\n",
    "# optionally drop combos that never traded:\n",
    "df_res = df_res[df_res[\"Trades\"] > 0]\n",
    "\n",
    "if not df_res.empty:\n",
    "    best = df_res.sort_values(\"PnL\", ascending=False).iloc[0]\n",
    "    print(\"\\nüèÜ Best combo by PnL:\\n\", best)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No trades fired on any combo. Try widening your thresholds.\")\n",
    "\n",
    "print(\"\\nAll results:\\n\", df_res.sort_values(\"PnL\", ascending=False))\n"
   ],
   "id": "9f7cbf306d05056f",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hyper-search:   0%|          | 0/50 [00:00<?, ?combo/s]C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[col] = out if out is not None else pd.NA\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"atr\"] = atr if atr is not None else pd.NA\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"atr_20\"] = atr20 if atr20 is not None else pd.NA\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rsi\"] = rsi if rsi is not None else pd.NA\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:96: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"macd\"]  = macd.iloc[:, 0]\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:97: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"macds\"] = macd.iloc[:, 1]\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"obv\"] = obv if obv is not None else pd.NA\n",
      "C:\\Users\\sreej\\projects\\zerodha-bot\\algo\\features.py:109: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"rv20\"] = (\n",
      "Hyper-search:   2%|‚ñè         | 1/50 [01:26<1:10:41, 86.57s/combo]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee696284c8a7f903"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kitebot)",
   "language": "python",
   "name": "kitebot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
