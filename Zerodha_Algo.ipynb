{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f806b577-8ec3-4920-b89e-1af9ba48457f",
   "metadata": {},
   "source": [
    "## Data log of entries, exits and P&L"
   ]
  },
  {
   "cell_type": "code",
   "id": "e300d673-eae7-4a40-bc5b-e5045b5b6994",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T09:46:01.695820Z",
     "start_time": "2025-06-24T09:46:01.678512Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# bt_df is the DataFrame returned by backtest()\n",
    "contract_size = 1  # for equity\n",
    "\n",
    "# Make sure bt_df is indexed by the `date` column:\n",
    "df = bt_df.set_index(\"date\")\n",
    "\n",
    "# Extract entry & exit rows\n",
    "entries = df[df.signal.isin([\"BUY\",\"SELL\"])].copy()\n",
    "exits   = df[df.signal == \"EXIT\"].copy()\n",
    "\n",
    "trades = []\n",
    "# Iterate over matching entry/exit pairs\n",
    "for (entry_time, ent_row), (exit_time, ex_row) in zip(entries.iterrows(), exits.iterrows()):\n",
    "    side        = ent_row.signal\n",
    "    entry_price = ent_row.close\n",
    "    exit_price  = ex_row.close\n",
    "    qty         = int(ent_row.qty)\n",
    "    notional    = entry_price * qty * contract_size\n",
    "    pnl         = float(ex_row.pnl)\n",
    "    duration    = exit_time - entry_time\n",
    "\n",
    "    trades.append({\n",
    "        \"side\":        side,\n",
    "        \"entry_time\":  entry_time,   # now a Timestamp\n",
    "        \"exit_time\":   exit_time,    # now a Timestamp\n",
    "        \"entry_price\": entry_price,\n",
    "        \"exit_price\":  exit_price,\n",
    "        \"qty\":         qty,\n",
    "        \"notional\":    notional,\n",
    "        \"pnl\":         pnl,\n",
    "        \"duration\":    duration,\n",
    "    })\n",
    "\n",
    "report = pd.DataFrame(trades)\n",
    "print(report.to_string(index=False))\n",
    "print(f\"\\nTOTAL PnL: ₹{report.pnl.sum():.2f}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "side                entry_time                 exit_time  entry_price  exit_price  qty  notional    pnl        duration\n",
      " BUY 2025-04-25 15:00:00+05:30 2025-04-28 13:15:00+05:30       1303.6      1368.9    7    9125.2  457.1 2 days 22:15:00\n",
      " BUY 2025-04-28 14:20:00+05:30 2025-05-05 09:40:00+05:30       1366.1      1438.4    7    9562.7  506.1 6 days 19:20:00\n",
      " BUY 2025-05-05 10:10:00+05:30 2025-05-06 11:15:00+05:30       1435.5      1412.0    6    8613.0 -141.0 1 days 01:05:00\n",
      "SELL 2025-05-08 09:50:00+05:30 2025-05-12 13:40:00+05:30       1409.8      1431.0    7    9868.6 -148.4 4 days 03:50:00\n",
      " BUY 2025-05-13 09:20:00+05:30 2025-05-22 09:45:00+05:30       1431.0      1408.4    6    8586.0 -135.6 9 days 00:25:00\n",
      " BUY 2025-05-23 11:10:00+05:30 2025-06-02 09:15:00+05:30       1430.5      1401.1    6    8583.0 -176.4 9 days 22:05:00\n",
      "SELL 2025-06-02 09:40:00+05:30 2025-06-03 10:20:00+05:30       1400.5      1422.5    7    9803.5 -154.0 1 days 00:40:00\n",
      " BUY 2025-06-05 11:20:00+05:30 2025-06-13 09:20:00+05:30       1443.7      1419.8    6    8662.2 -143.4 7 days 22:00:00\n",
      "\n",
      "TOTAL PnL: ₹64.40\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T10:38:06.486526Z",
     "start_time": "2025-06-26T10:38:02.784741Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ── Intraday scalping back-test (Reliance) ───────────────────────────\n",
    "#\n",
    "# The only change: build features **before** calling backtest().\n",
    "# Everything else (parameters, model, etc.) stays the same.\n",
    "# --------------------------------------------------------------------\n",
    "\n",
    "# 1️⃣ Imports\n",
    "from algo.broker     import KiteWrapper\n",
    "from algo.config     import load_config\n",
    "from algo.features   import add_indicators               # ← already toggles\n",
    "from algo.model      import load_or_train\n",
    "from algo.backtester import backtest\n",
    "import pandas as pd\n",
    "\n",
    "# 2️⃣ Parameters  ─────────────────────────────────────────────────────\n",
    "INTERVAL   = \"3minute\"\n",
    "TRAIN_DAYS = 180\n",
    "TEST_DAYS  = 20\n",
    "\n",
    "CAPITAL    = 100_000\n",
    "SL_PCT     = 0.0010\n",
    "TP_PCT     = 0.0025\n",
    "TRAIL_PCT  = 0.0025\n",
    "HOLD_MAX   = 15\n",
    "\n",
    "UPPER_PROB = 0.63\n",
    "LOWER_PROB = 0.36\n",
    "\n",
    "# 3️⃣ Fetch & prepare training data  ─────────────────────────────────\n",
    "cfg        = load_config()\n",
    "broker     = KiteWrapper(cfg)\n",
    "\n",
    "hist_train = broker.history(days=TRAIN_DAYS, interval=INTERVAL)\n",
    "print(\"Train interval:\", pd.infer_freq(hist_train.index[:10]))\n",
    "print(f\"TRAIN: {len(hist_train):,} bars  |  \"\n",
    "      f\"{hist_train.index.min()}  →  {hist_train.index.max()}\")\n",
    "\n",
    "df_train   = add_indicators(hist_train)          # ← compute all features\n",
    "model      = load_or_train(df_train, retrain=True)\n",
    "\n",
    "# 4️⃣ Fetch & prepare test slice  ────────────────────────────────────\n",
    "hist_test  = broker.history(days=TEST_DAYS, interval=INTERVAL)\n",
    "print(f\"TEST : {len(hist_test):,} bars  |  \"\n",
    "      f\"{hist_test.index.min()}  →  {hist_test.index.max()}\")\n",
    "\n",
    "df_test    = add_indicators(hist_test)           # ← compute all features\n",
    "\n",
    "# 5️⃣ Run back-test  (logic now matches live loop 1-for-1)  ──────────\n",
    "bt_df, metrics = backtest(\n",
    "    df_test,                      # <-- pass **feature-enriched** DataFrame\n",
    "    model=model,\n",
    "    capital=CAPITAL,\n",
    "    contract_size=1,\n",
    "    sl_pct=SL_PCT,\n",
    "    tp_pct=TP_PCT,\n",
    "    trail_pct=TRAIL_PCT,\n",
    "    hold_max=HOLD_MAX,\n",
    "    upper=UPPER_PROB,\n",
    "    lower=LOWER_PROB,\n",
    ")\n",
    "\n",
    "# 6️⃣ Review results  ────────────────────────────────────────────────\n",
    "print(\"Back-test metrics:\", metrics)\n"
   ],
   "id": "a22083029cea9fb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interval: 3min\n",
      "TRAIN: 15,278 bars  |  2024-12-30 09:15:00+05:30  →  2025-06-26 10:36:00+05:30\n",
      "Building X … done  (0.0s)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 39\u001B[39m\n\u001B[32m     35\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mTRAIN: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlen\u001B[39m(hist_train)\u001B[38;5;132;01m:\u001B[39;00m\u001B[33m,\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m bars  |  \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m     36\u001B[39m       \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhist_train.index.min()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m  →  \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mhist_train.index.max()\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m)\n\u001B[32m     38\u001B[39m df_train   = add_indicators(hist_train)          \u001B[38;5;66;03m# ← compute all features\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m39\u001B[39m model      = load_or_train(df_train, retrain=\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[32m     41\u001B[39m \u001B[38;5;66;03m# 4️⃣ Fetch & prepare test slice  ────────────────────────────────────\u001B[39;00m\n\u001B[32m     42\u001B[39m hist_test  = broker.history(days=TEST_DAYS, interval=INTERVAL)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\projects\\zerodha-bot\\algo\\model.py:104\u001B[39m, in \u001B[36mload_or_train\u001B[39m\u001B[34m(df_feat, retrain)\u001B[39m\n\u001B[32m    101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m joblib.load(_MODELPATH)\n\u001B[32m    103\u001B[39m X, y = _prepare_xy(df_feat)\n\u001B[32m--> \u001B[39m\u001B[32m104\u001B[39m X_tr, X_val, y_tr, y_val = train_test_split(X, y, test_size=\u001B[32m0.2\u001B[39m, shuffle=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m    106\u001B[39m pipe = _build_pipe().fit(X_tr, y_tr)\n\u001B[32m    107\u001B[39m acc  = accuracy_score(y_val, pipe.predict(X_val))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\kitebot\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:218\u001B[39m, in \u001B[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001B[39m\u001B[34m(*args, **kwargs)\u001B[39m\n\u001B[32m    212\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m    213\u001B[39m     \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[32m    214\u001B[39m         skip_parameter_validation=(\n\u001B[32m    215\u001B[39m             prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[32m    216\u001B[39m         )\n\u001B[32m    217\u001B[39m     ):\n\u001B[32m--> \u001B[39m\u001B[32m218\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m func(*args, **kwargs)\n\u001B[32m    219\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m InvalidParameterError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[32m    220\u001B[39m     \u001B[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001B[39;00m\n\u001B[32m    221\u001B[39m     \u001B[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001B[39;00m\n\u001B[32m    222\u001B[39m     \u001B[38;5;66;03m# the name of the estimator by the name of the function in the error\u001B[39;00m\n\u001B[32m    223\u001B[39m     \u001B[38;5;66;03m# message to avoid confusion.\u001B[39;00m\n\u001B[32m    224\u001B[39m     msg = re.sub(\n\u001B[32m    225\u001B[39m         \u001B[33mr\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[33m\\\u001B[39m\u001B[33mw+ must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    226\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mparameter of \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc.\u001B[34m__qualname__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m must be\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    227\u001B[39m         \u001B[38;5;28mstr\u001B[39m(e),\n\u001B[32m    228\u001B[39m     )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\kitebot\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2919\u001B[39m, in \u001B[36mtrain_test_split\u001B[39m\u001B[34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001B[39m\n\u001B[32m   2916\u001B[39m arrays = indexable(*arrays)\n\u001B[32m   2918\u001B[39m n_samples = _num_samples(arrays[\u001B[32m0\u001B[39m])\n\u001B[32m-> \u001B[39m\u001B[32m2919\u001B[39m n_train, n_test = _validate_shuffle_split(\n\u001B[32m   2920\u001B[39m     n_samples, test_size, train_size, default_test_size=\u001B[32m0.25\u001B[39m\n\u001B[32m   2921\u001B[39m )\n\u001B[32m   2923\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m:\n\u001B[32m   2924\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m stratify \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\anaconda3\\envs\\kitebot\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:2499\u001B[39m, in \u001B[36m_validate_shuffle_split\u001B[39m\u001B[34m(n_samples, test_size, train_size, default_test_size)\u001B[39m\n\u001B[32m   2496\u001B[39m n_train, n_test = \u001B[38;5;28mint\u001B[39m(n_train), \u001B[38;5;28mint\u001B[39m(n_test)\n\u001B[32m   2498\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_train == \u001B[32m0\u001B[39m:\n\u001B[32m-> \u001B[39m\u001B[32m2499\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2500\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mWith n_samples=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m, test_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m and train_size=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[33m, the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2501\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mresulting train set will be empty. Adjust any of the \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2502\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33maforementioned parameters.\u001B[39m\u001B[33m\"\u001B[39m.format(n_samples, test_size, train_size)\n\u001B[32m   2503\u001B[39m     )\n\u001B[32m   2505\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m n_train, n_test\n",
      "\u001B[31mValueError\u001B[39m: With n_samples=0, test_size=0.2 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-26T11:11:22.043767Z",
     "start_time": "2025-06-26T11:11:19.075775Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Intraday scalping back-test  (Reliance, 3-minute bars)\n",
    "\n",
    "from algo.broker       import KiteWrapper\n",
    "from algo.config       import load_config\n",
    "from algo.features     import add_indicators\n",
    "from algo.model        import load_or_train\n",
    "from algo.backtester   import backtest\n",
    "import pandas as pd\n",
    "\n",
    "# ─── parameters ──────────────────────────────────────────────────────\n",
    "INTERVAL     = \"3minute\"\n",
    "TRAIN_DAYS   = 180\n",
    "TEST_DAYS    = 20\n",
    "\n",
    "CAPITAL      = 100_000\n",
    "SL_PCT       = 0.0010\n",
    "TP_PCT       = 0.0025\n",
    "TRAIL_PCT    = 0.0015\n",
    "HOLD_MAX     = 15\n",
    "\n",
    "UPPER_PROB   = 0.63\n",
    "LOWER_PROB   = 0.36\n",
    "\n",
    "# ─── fetch & train ───────────────────────────────────────────────────\n",
    "cfg        = load_config()\n",
    "broker     = KiteWrapper(cfg)\n",
    "\n",
    "hist_train = broker.history(days=TRAIN_DAYS, interval=INTERVAL)\n",
    "print(\"Train interval:\", pd.infer_freq(hist_train.index[:10]))\n",
    "print(f\"TRAIN: {len(hist_train):,} bars  |  \"\n",
    "      f\"{hist_train.index.min()} → {hist_train.index.max()}\")\n",
    "\n",
    "model      = load_or_train(add_indicators(hist_train), retrain=False)\n",
    "\n",
    "# ─── test slice & back-test ──────────────────────────────────────────\n",
    "hist_test  = broker.history(days=TEST_DAYS, interval=INTERVAL)\n",
    "print(f\"TEST : {len(hist_test):,} bars  |  \"\n",
    "      f\"{hist_test.index.min()} → {hist_test.index.max()}\")\n",
    "\n",
    "trades, metrics = backtest(\n",
    "    hist_test,\n",
    "    model=model,\n",
    "    capital=CAPITAL,\n",
    "    contract_size=1,\n",
    "    sl_pct=SL_PCT,\n",
    "    tp_pct=TP_PCT,\n",
    "    trail_pct=TRAIL_PCT,\n",
    "    hold_max=HOLD_MAX,\n",
    "    upper=UPPER_PROB,\n",
    "    lower=LOWER_PROB,\n",
    ")\n",
    "\n",
    "print(\"\\nBack-test metrics:\", metrics)\n"
   ],
   "id": "97f873867e5bc630",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train interval: 3min\n",
      "TRAIN: 15,289 bars  |  2024-12-30 09:15:00+05:30 → 2025-06-26 11:09:00+05:30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[32m~\\AppData\\Local\\Temp\\ipykernel_53920\\2177303628.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m()\u001B[39m\n\u001B[32m     29\u001B[39m print(\u001B[33m\"Train interval:\"\u001B[39m, pd.infer_freq(hist_train.index[:\u001B[32m10\u001B[39m]))\n\u001B[32m     30\u001B[39m print(f\"TRAIN: {len(hist_train):,} bars  |  \"\n\u001B[32m     31\u001B[39m       f\"{hist_train.index.min()} → {hist_train.index.max()}\")\n\u001B[32m     32\u001B[39m \n\u001B[32m---> \u001B[39m\u001B[32m33\u001B[39m model      = load_or_train(add_indicators(hist_train), retrain=\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[32m     34\u001B[39m \n\u001B[32m     35\u001B[39m \u001B[38;5;66;03m# ─── test slice & back-test ──────────────────────────────────────────\u001B[39;00m\n\u001B[32m     36\u001B[39m hist_test  = broker.history(days=TEST_DAYS, interval=INTERVAL)\n",
      "\u001B[32m~\\projects\\zerodha-bot\\algo\\features.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(df)\u001B[39m\n\u001B[32m     48\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m n \u001B[38;5;28;01min\u001B[39;00m (\u001B[32m3\u001B[39m, \u001B[32m4\u001B[39m, \u001B[32m8\u001B[39m, \u001B[32m9\u001B[39m, \u001B[32m21\u001B[39m):\n\u001B[32m     49\u001B[39m         df[\u001B[33mf\"ema_{n}\"\u001B[39m] = ta.ema(df[\u001B[33m\"close\"\u001B[39m], length=n)\n\u001B[32m     50\u001B[39m \n\u001B[32m     51\u001B[39m     \u001B[38;5;66;03m# ── ATRs ──────────────────────────────────────────────────────────\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m     df[\u001B[33m\"atr\"\u001B[39m]    = _safe(ta.atr, df[\u001B[33m\"high\"\u001B[39m], df[\u001B[33m\"low\"\u001B[39m], df[\u001B[33m\"close\"\u001B[39m], length=\u001B[32m14\u001B[39m) \u001B[38;5;28;01mor\u001B[39;00m pd.NA\n\u001B[32m     53\u001B[39m     df[\u001B[33m\"atr_20\"\u001B[39m] = _safe(ta.atr, df[\u001B[33m\"high\"\u001B[39m], df[\u001B[33m\"low\"\u001B[39m], df[\u001B[33m\"close\"\u001B[39m], length=\u001B[32m20\u001B[39m) \u001B[38;5;28;01mor\u001B[39;00m pd.NA\n\u001B[32m     54\u001B[39m \n\u001B[32m     55\u001B[39m     \u001B[38;5;66;03m# ── RSI(14) ───────────────────────────────────────────────────────\u001B[39;00m\n",
      "\u001B[32m~\\anaconda3\\envs\\kitebot\\Lib\\site-packages\\pandas\\core\\generic.py\u001B[39m in \u001B[36m?\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1575\u001B[39m     @final\n\u001B[32m   1576\u001B[39m     \u001B[38;5;28;01mdef\u001B[39;00m __nonzero__(self) -> NoReturn:\n\u001B[32m-> \u001B[39m\u001B[32m1577\u001B[39m         raise ValueError(\n\u001B[32m   1578\u001B[39m             \u001B[33mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001B[39m\n\u001B[32m   1579\u001B[39m             \u001B[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001B[39m\n\u001B[32m   1580\u001B[39m         )\n",
      "\u001B[31mValueError\u001B[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "8521813a116a5afb"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kitebot)",
   "language": "python",
   "name": "kitebot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
