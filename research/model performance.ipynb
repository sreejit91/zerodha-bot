{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T03:38:55.827678Z",
     "start_time": "2025-07-08T03:38:50.527829Z"
    }
   },
   "cell_type": "code",
   "source": "pip install --force-reinstall lightgbm",
   "id": "4f73a8e90a37b7e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\r\n",
      "  Using cached lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\r\n",
      "Collecting numpy>=1.17.0 (from lightgbm)\r\n",
      "  Using cached numpy-2.3.1-cp313-cp313-macosx_11_0_arm64.whl.metadata (171 kB)\r\n",
      "Collecting scipy (from lightgbm)\r\n",
      "  Using cached scipy-1.16.0-cp313-cp313-macosx_12_0_arm64.whl.metadata (61 kB)\r\n",
      "Using cached lightgbm-4.6.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\r\n",
      "Using cached numpy-2.3.1-cp313-cp313-macosx_11_0_arm64.whl (14.2 MB)\r\n",
      "Using cached scipy-1.16.0-cp313-cp313-macosx_12_0_arm64.whl (28.5 MB)\r\n",
      "Installing collected packages: numpy, scipy, lightgbm\r\n",
      "\u001B[2K  Attempting uninstall: numpy\r\n",
      "\u001B[2K    Found existing installation: numpy 2.3.1\r\n",
      "\u001B[2K    Uninstalling numpy-2.3.1:\r\n",
      "\u001B[2K      Successfully uninstalled numpy-2.3.1\r\n",
      "\u001B[2K  Attempting uninstall: scipyâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m0/3\u001B[0m [numpy]\r\n",
      "\u001B[2K    Found existing installation: scipy 1.16.0[0m \u001B[32m0/3\u001B[0m [numpy]\r\n",
      "\u001B[2K    Uninstalling scipy-1.16.0:â•º\u001B[0m\u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K      Successfully uninstalled scipy-1.16.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K  Attempting uninstall: lightgbm[0m\u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K    Found existing installation: lightgbm 4.6.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K    Uninstalling lightgbm-4.6.0:[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K      Successfully uninstalled lightgbm-4.6.0â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m1/3\u001B[0m [scipy]\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m3/3\u001B[0m [lightgbm]2/3\u001B[0m [lightgbm]\r\n",
      "\u001B[1A\u001B[2K\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "pandas-stubs 2.3.0.250703 requires types-pytz>=2022.1.1, which is not installed.\u001B[0m\u001B[31m\r\n",
      "\u001B[0mSuccessfully installed lightgbm-4.6.0 numpy-2.3.1 scipy-1.16.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-08T03:43:16.804446Z",
     "start_time": "2025-07-08T03:42:04.048154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# â”€â”€ AUC-check cell (updated for N_AHEAD) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "from algo import load_config\n",
    "from algo import KiteWrapper\n",
    "from research.features import add_indicators, FEATURES\n",
    "from research.model    import load_or_train, LOOKBACK, N_AHEAD        # â† import constants\n",
    "\n",
    "# 1) Fetch 6-month history & build indicators\n",
    "cfg    = load_config()\n",
    "broker = KiteWrapper(cfg)\n",
    "hist   = broker.history(days=180, interval=\"3minute\", tradingsymbol=\"IDEA\")\n",
    "df_all = add_indicators(hist).ffill()\n",
    "\n",
    "# 2) Binary target: price N_AHEAD bars ahead higher than now?\n",
    "df_all[\"y\"] = (df_all[\"close\"].shift(-N_AHEAD) > df_all[\"close\"]).astype(int)\n",
    "\n",
    "# 3) Build sliding windows (feature matrix X) that match live pipeline\n",
    "windows, labels = [], []\n",
    "for i in range(LOOKBACK, len(df_all) - N_AHEAD):\n",
    "    win = df_all.iloc[i - LOOKBACK : i][FEATURES].to_numpy().ravel()\n",
    "    windows.append(win)\n",
    "    labels.append(df_all[\"y\"].iat[i])\n",
    "\n",
    "X = np.asarray(windows, dtype=\"float32\")\n",
    "y = np.asarray(labels, dtype=\"int8\")\n",
    "\n",
    "# 4) Train / reload LightGBM pipeline (set retrain=True once after feature edits)\n",
    "model = load_or_train(df_all.iloc[: -(LOOKBACK + N_AHEAD)], retrain=True)\n",
    "\n",
    "# 5) Forward-walk CV AUC\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "auc_scores = cross_val_score(model, X, y, cv=tscv, scoring=\"roc_auc\", n_jobs=-1)\n",
    "\n",
    "print(\"Fold AUCs :\", np.round(auc_scores, 3))\n",
    "print(\"Median AUC:\", round(np.median(auc_scores), 3))\n"
   ],
   "id": "initial_id",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KiteWrapper] initialized: symbol=RELIANCE on exch=NSE\n",
      "[history] start: days=180, interval=3minute, symbol=IDEA\n",
      "[history] range UTC-naive: 2025-01-09 03:42:04.067771 â†’ 2025-07-08 03:42:04.067771\n",
      "[history] token=3677697\n",
      "[history] got 8375 bars, cursorâ†’2025-04-17 15:30:00\n",
      "[history] got 6875 bars, cursorâ†’2025-07-07 15:30:00\n",
      "[history] empty data for 2025-07-07 15:30:00->2025-07-08 03:42:04.067771, breaking loop\n",
      "[history] complete 15250 bars 2025-01-09 09:15:00 â†’ 2025-07-07 15:27:00\n",
      "ðŸ”§  Training started at 09:12:08\n",
      "âœ…  Training finished in 9.4s\n",
      "Validation accuracy: 0.557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold AUCs : [0.499 0.495 0.555 0.504 0.501 0.449 0.543 0.494 0.521 0.53 ]\n",
      "Median AUC: 0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T05:53:48.515622Z",
     "start_time": "2025-07-08T05:53:22.386520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# research/test_auc_with_imbalance.py\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score\n",
    "\n",
    "# 1) Load the merged DataFrame you just created\n",
    "df = pd.read_csv(\n",
    "    \"merged_RELIANCE_imb_3m_2025-07-08.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\",\n",
    ")\n",
    "\n",
    "# 2) Import your research-model pipeline & constants\n",
    "from research.model    import load_or_train, N_AHEAD\n",
    "from research.features import FEATURES\n",
    "from research.config   import load_config\n",
    "from algo import KiteWrapper\n",
    "\n",
    "# 3) (Re)train on the full merged history\n",
    "#    â€” so your pipeline now *sees* imb_mean / imb_std\n",
    "cfg     = load_config()\n",
    "broker  = KiteWrapper(cfg)\n",
    "hist_full = broker.history(days=180, interval=\"3minute\", tradingsymbol=cfg.tradingsymbol)\n",
    "df_full   = pd.read_csv(\n",
    "    \"merged_RELIANCE_imb_3m_2025-07-08.csv\",\n",
    "    parse_dates=[\"timestamp\"],\n",
    "    index_col=\"timestamp\"\n",
    ").pipe(lambda d: d.ffill())  # fill any NaNs\n",
    "\n",
    "model = load_or_train(df_full, retrain=True)  # retrain=True because we changed FEATURES\n",
    "\n",
    "# 4) Prepare X, y for the most recent day (or full period)\n",
    "X = df_full[FEATURES]\n",
    "y = (df_full[\"close\"].shift(-N_AHEAD) > df_full[\"close\"]).astype(int)\n",
    "\n",
    "# drop the last N_AHEAD rows (they have no target)\n",
    "X, y = X.iloc[:-N_AHEAD], y.iloc[:-N_AHEAD]\n",
    "\n",
    "# 5) TimeSeriesSplit â†’ cross-val AUC\n",
    "tscv = TimeSeriesSplit(n_splits=10)\n",
    "auc_scores = cross_val_score(\n",
    "    model, X, y,\n",
    "    cv=tscv,\n",
    "    scoring=\"roc_auc\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "# 6) Report\n",
    "print(\"Fold AUCs :\", np.round(auc_scores, 3))\n",
    "print(\"Median AUC:\", np.round(np.median(auc_scores), 3))\n"
   ],
   "id": "bacd6befd2790171",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KiteWrapper] initialized: symbol=RELIANCE on exch=NSE\n",
      "[history] start: days=180, interval=3minute, symbol=RELIANCE\n",
      "[history] range UTC-naive: 2025-01-09 05:53:22.446389 â†’ 2025-07-08 05:53:22.446389\n",
      "[history] token=738561\n",
      "[history] got 8375 bars, cursorâ†’2025-04-17 15:30:00\n",
      "[history] got 6875 bars, cursorâ†’2025-07-07 15:30:00\n",
      "[history] empty data for 2025-07-07 15:30:00->2025-07-08 05:53:22.446389, breaking loop\n",
      "[history] complete 15250 bars 2025-01-09 09:15:00 â†’ 2025-07-07 15:27:00\n",
      "ðŸ”§  Training started at 11:23:23\n",
      "âœ…  Training finished in 9.1s\n",
      "Validation accuracy: 0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Library/Frameworks/Python.framework/Versions/3.13/lib/python3.13/multiprocessing/queues.py:120: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  return _ForkingPickler.loads(res)\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold AUCs : [0.499 0.573 0.557 0.522 0.492 0.542 0.531 0.5   0.523 0.543]\n",
      "Median AUC: 0.527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/sreejit/PycharmProjects/zerodha-bot/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-08T05:40:47.195717Z",
     "start_time": "2025-07-08T05:40:47.125958Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 1) load whateverâ€™s in the CSV so far:\n",
    "df = pd.read_csv(\n",
    "    \"imb_tape_2025-07-08.csv\",\n",
    "    parse_dates=[\"ts_utc\"],\n",
    "    index_col=\"ts_utc\"\n",
    ")\n",
    "\n",
    "# 2) resample to 3-min and compute mean/std\n",
    "bars = df[\"imb\"].resample(\"3T\").agg([\"mean\",\"std\"])\n",
    "\n",
    "print(f\"Bars so far: {len(bars)} (out of 125 expected)\")\n",
    "print(bars.head(), \"\\nâ€¦\\n\", bars.tail())\n"
   ],
   "id": "f741b81a7ab23393",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bars so far: 13 (out of 125 expected)\n",
      "                         mean       std\n",
      "ts_utc                                 \n",
      "2025-07-08 05:03:00 -0.002628  0.652623\n",
      "2025-07-08 05:06:00 -0.103327  0.621978\n",
      "2025-07-08 05:09:00 -0.162325  0.629816\n",
      "2025-07-08 05:12:00 -0.245400  0.535625\n",
      "2025-07-08 05:15:00  0.039151  0.583979 \n",
      "â€¦\n",
      "                          mean       std\n",
      "ts_utc                                 \n",
      "2025-07-08 05:27:00 -0.313418  0.561300\n",
      "2025-07-08 05:30:00 -0.416137  0.487249\n",
      "2025-07-08 05:33:00 -0.185370  0.631623\n",
      "2025-07-08 05:36:00 -0.367081  0.584939\n",
      "2025-07-08 05:39:00 -0.422671  0.447051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_y/qb2g5b655jqfc5_hr5xjb1sr0000gn/T/ipykernel_3792/683748000.py:11: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  bars = df[\"imb\"].resample(\"3T\").agg([\"mean\",\"std\"])\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# %%bash\n",
    "# ensure your project root is on PYTHONPATH if needed\n",
    "# export PYTHONPATH=\"${PYTHONPATH}:/path/to/your/project\"\n",
    "\n",
    "# %%python\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# adjust this import if your code lives elsewhere\n",
    "from research.model import _prepare_xy\n",
    "\n",
    "# 1ï¸âƒ£ Load your data from CSV instead of Parquet\n",
    "csv_path = \"merged_RELIANCE_imb_3m_2025-07-08.csv\"  # â† change to your file\n",
    "# If your datetime column is named 'timestamp':\n",
    "df = pd.read_csv(csv_path, parse_dates=['timestamp'], index_col='timestamp')\n",
    "# Alternatively, if datetime is the first column:\n",
    "# df = pd.read_csv(csv_path, index_col=0, parse_dates=True)\n",
    "\n",
    "print(\"âœ… Loaded DataFrame:\", df.shape)\n",
    "display(df.head())  # if you want to peek at columns\n",
    "\n",
    "# 2ï¸âƒ£ Prepare features & labels\n",
    "X, y = _prepare_xy(df)\n",
    "print(f\"ðŸ”§ Prepared X shape = {X.shape}, y shape = {y.shape}\")\n",
    "\n",
    "# 3ï¸âƒ£ Define the hyperparameter tuner\n",
    "def tune_hyperparameters(X: np.ndarray, y: np.ndarray, n_iter: int = 50):\n",
    "    pipe = _build_pipe()\n",
    "    param_dist = {\n",
    "        \"gbm__num_leaves\":       randint(16, 128),\n",
    "        \"gbm__learning_rate\":    uniform(0.01, 0.19),\n",
    "        \"gbm__n_estimators\":     randint(100, 1000),\n",
    "        \"gbm__subsample\":        uniform(0.5, 0.5),\n",
    "        \"gbm__colsample_bytree\": uniform(0.5, 0.5),\n",
    "        \"gbm__reg_alpha\":        uniform(0.0, 1.0),\n",
    "        \"gbm__reg_lambda\":       uniform(0.0, 1.0),\n",
    "    }\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    search = RandomizedSearchCV(\n",
    "        pipe,\n",
    "        param_distributions=param_dist,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=tscv,\n",
    "        n_jobs=-1,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "    )\n",
    "    print(\"ðŸ”Ž Starting hyperparameter searchâ€¦\")\n",
    "    search.fit(X, y)\n",
    "    print(f\"\\nðŸ† Best CV AUC: {search.best_score_:.4f}\")\n",
    "    print(\"âœ¨ Best hyperparameters:\")\n",
    "    for k, v in search.best_params_.items():\n",
    "        print(f\"   â€¢ {k} = {v}\")\n",
    "    return search.best_estimator_\n",
    "\n",
    "# 4ï¸âƒ£ Run the search\n",
    "best_pipe = tune_hyperparameters(X, y, n_iter=100)\n",
    "\n",
    "# 5ï¸âƒ£ Save the tuned pipeline\n",
    "joblib.dump(best_pipe, \"best_lgbm_pipeline.pkl\")\n",
    "print(\"ðŸ’¾ Saved tuned model to best_lgbm_pipeline.pkl\")\n"
   ],
   "id": "3a070e6e74816d94"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from research.model import _build_pipe, _prepare_xy\n",
    "\n",
    "# 1ï¸âƒ£ Load your â€œallâ€inâ€ training data (same CSV you tuned on)\n",
    "train_csv = \"merged_RELIANCE_imb_3m_2025-07-08.csv\"\n",
    "df_train = pd.read_csv(train_csv, parse_dates=['timestamp'], index_col='timestamp')\n",
    "\n",
    "# 2ï¸âƒ£ Prepare X_train, y_train\n",
    "X_train, y_train = _prepare_xy(df_train)\n",
    "\n",
    "# 3ï¸âƒ£ Build pipeline with tuned hyperparameters\n",
    "best_params = {\n",
    "    'gbm__colsample_bytree': 0.5961445094043354,\n",
    "    'gbm__learning_rate':    0.017765037090630986,\n",
    "    'gbm__n_estimators':     104,\n",
    "    'gbm__num_leaves':       97,\n",
    "    'gbm__reg_alpha':        0.2785903390319586,\n",
    "    'gbm__reg_lambda':       0.17701048427674682,\n",
    "    'gbm__subsample':        0.5443512668785278,\n",
    "}\n",
    "\n",
    "pipe_final = _build_pipe()\n",
    "pipe_final.set_params(**best_params)\n",
    "\n",
    "# 4ï¸âƒ£ Fit on all training data\n",
    "pipe_final.fit(X_train, y_train)\n",
    "\n",
    "# 5ï¸âƒ£ Save your final model\n",
    "joblib.dump(pipe_final, \"final_lgbm_pipeline.pkl\")\n",
    "print(\"âœ… Final model trained and saved as final_lgbm_pipeline.pkl\")\n",
    "\n",
    "# 6ï¸âƒ£ (Optional) Evaluate on a hold-out CSV\n",
    "test_csv = \"imb_3m_2025-07-08.csv\"  # swap in your test file\n",
    "df_test = pd.read_csv(test_csv, parse_dates=['timestamp'], index_col='timestamp')\n",
    "X_test, y_test = _prepare_xy(df_test)\n",
    "y_pred = pipe_final.predict_proba(X_test)[:, 1]\n",
    "print(\"ðŸ Hold-out AUC:\", roc_auc_score(y_test, y_pred))\n"
   ],
   "id": "ce0127a470be6111"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# 1ï¸âƒ£ Peek at the first few rows to see what your datetime column is called\n",
    "import pandas as pd\n",
    "\n",
    "test_csv = \"imb_3m_2025-07-08.csv\"\n",
    "df_preview = pd.read_csv(test_csv, nrows=5)\n",
    "print(\"Columns in test file:\", list(df_preview.columns))\n",
    "display(df_preview.head())"
   ],
   "id": "1fb4a53eb046f661"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from research.model import _prepare_xy\n",
    "\n",
    "# 1ï¸âƒ£ Load your merged half-day CSV\n",
    "merged_csv = \"merged_RELIANCE_imb_3m_2025-07-08.csv\"\n",
    "df = pd.read_csv(merged_csv, index_col=0, parse_dates=True)\n",
    "\n",
    "# 2ï¸âƒ£ Split by rowâ€count (first 70% train, last 30% test)\n",
    "n = len(df)\n",
    "cut = int(0.7 * n)\n",
    "df_train, df_test = df.iloc[:cut], df.iloc[cut:]\n",
    "\n",
    "# 3ï¸âƒ£ Build X/y\n",
    "X_tr, y_tr = _prepare_xy(df_train)\n",
    "X_te, y_te = _prepare_xy(df_test)\n",
    "\n",
    "# 4ï¸âƒ£ Fit your tuned pipeline on the first 70%\n",
    "pipe = joblib.load(\"best_lgbm_pipeline.pkl\")\n",
    "pipe.fit(X_tr, y_tr)\n",
    "\n",
    "# 5ï¸âƒ£ Score on the last 30%\n",
    "y_pred = pipe.predict_proba(X_te)[:,1]\n",
    "print(\"Hold-out (last 30%) AUC:\", roc_auc_score(y_te, y_pred))\n"
   ],
   "id": "33b641f0fb360753"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# %%python\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1ï¸âƒ£ Import your constants and model\n",
    "from research.model import LOOKBACK         # number of bars per window (60) :contentReference[oaicite:0]{index=0}\n",
    "from features import FEATURES               # list of feature names (length=14) :contentReference[oaicite:1]{index=1}\n",
    "\n",
    "pipe = joblib.load(\"best_lgbm_pipeline.pkl\")\n",
    "model = pipe.named_steps[\"gbm\"]\n",
    "\n",
    "# 2ï¸âƒ£ Raw importances\n",
    "importances = model.feature_importances_    # shape = (LOOKBACK * len(FEATURES),)\n",
    "\n",
    "# 3ï¸âƒ£ Reshape into matrix: rows=lag steps, cols=features\n",
    "imp_matrix = importances.reshape(LOOKBACK, len(FEATURES))\n",
    "\n",
    "# 4ï¸âƒ£ Aggregate: mean importance per feature across all lags\n",
    "mean_imp = pd.Series(imp_matrix.mean(axis=0), index=FEATURES)\n",
    "mean_imp = mean_imp.sort_values()\n",
    "\n",
    "# 5ï¸âƒ£ Plot\n",
    "mean_imp.plot.barh(figsize=(8,6))\n",
    "plt.title(\"Mean LGBM Feature Importance (averaged over 60-bar window)\")\n",
    "plt.xlabel(\"Mean importance\")\n",
    "plt.tight_layout()\n"
   ],
   "id": "85a544b6c3f08ee5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from features import add_indicators\n",
    "import pandas as pd\n",
    "\n",
    "# 1ï¸âƒ£ Preview the merged fileâ€™s columns so you know what to load\n",
    "merged_csv = \"merged_RELIANCE_imb_3m_2025-07-08.csv\"\n",
    "print(\"Columns in merged file:\", pd.read_csv(merged_csv, nrows=0).columns.tolist())\n",
    "\n",
    "# 2ï¸âƒ£ Load the first 30 bars of just the OHLCV columns\n",
    "#    (swap 'open','high','low','close','volume' for whatever your column names actually are)\n",
    "df_raw = pd.read_csv(\n",
    "    merged_csv,\n",
    "    parse_dates=[\"ts_utc\"],    # this is your datetime column\n",
    "    index_col=\"ts_utc\"\n",
    ")\n",
    "df_slice = df_raw[[\"open\",\"high\",\"low\",\"close\",\"volume\"]].iloc[:30]\n",
    "\n",
    "# 3ï¸âƒ£ Run add_indicators in debug mode\n",
    "df_debug = add_indicators(df_slice, debug=True)\n",
    "\n",
    "# 4ï¸âƒ£ Inspect the printed output and df_debug to verify each series\n",
    "display(df_debug.head())\n"
   ],
   "id": "cf6fa153cfee2152"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5e9bef4c5dbb672d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
